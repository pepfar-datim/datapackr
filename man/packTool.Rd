% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/packTool.R
\name{packTool}
\alias{packTool}
\title{Pack a requested tool}
\usage{
packTool(
  model_data_path = NULL,
  snuxim_model_data_path = NULL,
  undistributed_mer_data = NULL,
  tool,
  datapack_name,
  country_uids,
  template_path,
  cop_year,
  output_folder,
  results_archive = TRUE,
  expand_formulas = FALSE,
  d2_session = dynGet("d2_default_session", inherits = TRUE)
)
}
\arguments{
\item{model_data_path}{Local filepath to a Data Pack model data file.}

\item{snuxim_model_data_path}{Local filepath to an SNUxIM Model Data file.}

\item{undistributed_mer_data}{Data from the \code{d$data$UndistributedMER}
dataset that can be provided while generating an OPU tool such that the
targets to be distributed will be sourced from this file.}

\item{tool}{Type of tool this function will create or interact with. Either
\code{OPU Data Pack} or \code{Data Pack}}

\item{datapack_name}{Name you would like associated with this Data Pack.
(Example: "Western Hemisphere", or "Caribbean Region", or "Kenya".)}

\item{country_uids}{Unique IDs for countries to include in the Data Pack.
For full list of these IDs, see \code{datapackr::valid_OrgUnits}.}

\item{template_path}{Local filepath to Data Pack template Excel (XLSX) file.
This file MUST NOT have any data validation formats present. If left
\code{NULL}, will select the default based on \code{cop_year} and \code{tool}.}

\item{cop_year}{COP Year to use for tailoring functions. Remember,
FY22 targets = COP21.}

\item{output_folder}{Local folder where you would like your Data Pack to be
saved upon export.}

\item{results_archive}{If TRUE, will export compiled results of all tests and
processes to output_folder.}

\item{d2_session}{DHIS2 Session id. R6 datimutils object which handles
authentication with DATIM.}
}
\value{
Exports a Data Pack or OPU Data Pack tool to Excel within
\code{output_folder}.
}
\description{
Generates a requested Data Pack or OPU Data Pack tool by taking an Excel
template file and combining it with data pulled from DATIM API to produce
a file ready for distribution.
}
